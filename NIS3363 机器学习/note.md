# 机器学习笔记

## 1. 评估与泛化

- **评估**：为了提高泛化能力。
- **Attribute 和 Feature 的区别**：
  - **Attribute**：显而易见。
  - **Feature**：更复杂的组合。
- **Few-shot/Zero-shot**：现在更倾向于使用少样本/零样本学习。
- **目标识别和图像识别的特征**：
  - 自动化特征提取。
  - 在深度学习出现之前，SVM 可以处理几千/几万维特征。
- **特定应用**：
  - 内容无关/伪造检测/图像载体传播其他信息。
  - 深度学习提取特征不好。
- **特征提取**：
  - 给予大量样本。
  - 人为告诉（频率域特征）。
- **回归任务**：处理连续变量。

## 2. 模型

- **假设（Hypothesis）**：概率值（可离散）。
- **真相（Groundtruth）**。
- **学习器（Learner）**：决策时使用的模型，如 NN、SVM、Boosting、贝叶斯网络。

### 2.1 最大化后验概率训练模型

在朴素贝叶斯中，目标是通过最大化后验概率来训练模型。贝叶斯定理给出了后验概率的公式：

\[
P(C|X) = \frac{P(X|C)P(C)}{P(X)}
\]

- \( P(C|X) \)：给定数据 \( X \) 时，属于类别 \( C \) 的后验概率。
- \( P(X|C) \)：给定类别 \( C \) 时，观察到数据 \( X \) 的似然概率。
- \( P(C) \)：类别 \( C \) 的先验概率。
- \( P(X) \)：数据 \( X \) 的总概率，通常作为常数来进行标准化。

在训练阶段，需要估计这些概率，特别是 \( P(C) \) 和 \( P(X|C) \)。朴素贝叶斯通过“朴素”假设（特征之间独立）将 \( P(X|C) \) 分解为多个特征条件概率的乘积，简化了计算：

\[
P(X|C) = \prod_{i=1}^{n} P(x_i|C)
\]

然后，选择最大化后验概率的类别 \( C \) 来进行分类：

\[
C_{MAP} = \arg\max_C P(C|X) = \arg\max_C \left( P(C) \prod_{i=1}^{n} P(x_i|C) \right)
\]

### 2.2 朴素贝叶斯的两种常见方法

朴素贝叶斯常见的两种变种基于不同的条件概率模型：

- **高斯朴素贝叶斯（Gaussian Naive Bayes）**：

  假设每个特征在给定类别下服从高斯分布（正态分布）。对于每个特征 \( x_i \)，假设其条件分布 \( P(x_i|C) \) 是高斯分布，因此需要估计均值和方差。

  公式：

  \[
  P(x_i | C) = \frac{1}{\sqrt{2\pi\sigma_C^2}} \exp\left(-\frac{(x_i - \mu_C)^2}{2\sigma_C^2}\right)
  \]

  其中 \( \mu_C \) 和 \( \sigma_C^2 \) 分别是类别 \( C \) 下特征 \( x_i \) 的均值和方差。

- **多项式朴素贝叶斯（Multinomial Naive Bayes）**：

  适用于离散特征，尤其是在文本分类中，假设每个特征（如词频）服从多项式分布。它依赖于词频的出现概率，并计算每个类别下每个词汇的条件概率。

  公式：

  \[
  P(x_i | C) = \frac{(n_i + \alpha)}{(N_C + \alpha V)}
  \]

  其中 \( n_i \) 是类别 \( C \) 下特征 \( x_i \) 的出现次数，\( N_C \) 是类别 \( C \) 下所有特征的总数，\(\alpha\) 是平滑参数，\( V \) 是词汇表大小。

### 2.3 独立性假设太强

朴素贝叶斯的一个主要假设是特征之间是条件独立的，即给定类别后，特征之间相互独立。然而，在实际应用中，特征往往不是完全独立的。例如，在文本分类中，词汇之间通常存在一定的关联性（如“机器学习”和“人工智能”之间的关系）。这个假设虽然简单，但在许多情况下，即使特征之间不完全独立，朴素贝叶斯仍能提供合理的分类结果，特别是在数据量较大时。

### 2.4 集成学习中的子分类器

由于朴素贝叶斯假设特征独立性太强，可能导致某些任务的表现不理想，因此在集成学习中，朴素贝叶斯可以作为一个基分类器进行组合。例如，在随机森林、梯度提升树等集成方法中，可以使用朴素贝叶斯作为子分类器之一，这样可以通过多样化的基分类器来提高模型的鲁棒性和准确性。

- **集成学习**：通过组合多个基分类器（如决策树、朴素贝叶斯等），可以减少模型的偏差和方差，提升整体性能。每个基分类器可能在某些区域表现更好，而集成多个分类器有助于避免过拟合并提高泛化能力。

## 3. 过拟合与欠拟合

- **过拟合**：高考考不好。
- **欠拟合**：教的时候都没学好。

### 3.1 假设空间

- **学习过程**：在所有假设组成中找到好瓜（n1*n2*n3+1）。
- **归纳偏好**：Bias。
- **如果有多个假设与观察一致，选择最简单的一个**：
  - 线性 > 非线性。
  - 低次 > 高次。
- **NFL 定理**：样本完全随机分布，模型选择是无意义的。

### 3.2 NFL 定理

- **简单起见**，假设样本空间 \( \mathcal{X} \) 和假设空间 \( \mathcal{H} \) 离散，
  令 \( P(h|X, \mathcal{S}_a) \) 代表算法 \( \mathcal{S}_a \) 基于训练数据 \( X \) 产生假设 \( h \) 的概率，
  \( f \) 代表要学习的目标函数。
  在训练集之外，所有样本上的总误差差为：

  \[
  E_{ote}(\mathcal{S}_a | X, f) = \sum_h \sum_{x \in \mathcal{X} - X} P(x) \mathbb{I}(h(x) \neq f(x)) P(h | X, \mathcal{S}_a)
  \]

- **考虑二分类问题**，目标函数可以为任何函数 \( \mathcal{X} \to \{0,1\} \)，
  函数空间间为 \( \{0,1\}^{|\mathcal{X}|} \)，
  对所有可能的 \( f \) 按均匀分布对误差求和，有：

  \[
  \sum_f E_{ote}(\mathcal{S}_a | X, f) = \sum_f \sum_h \sum_{x \in \mathcal{X} - X} P(x) \mathbb{I}(h(x) \neq f(x)) P(h | X, \mathcal{S}_a)
  \]
  模型对测试集的误差
  根据 NFL 定理的推导，我们可以得出：

在所有可能的学习任务中，没有一个算法在测试集上表现得比其他算法更好，除非我们有关于数据分布的某种先验知识。
如果目标函数是随机的（没有特定结构），那么所有算法的测试误差期望是相同的，这意味着在这种情况下，任何尝试优化模型泛化性能的努力都是徒劳的。
不同学习算法的表现依赖于问题本身的结构。如果我们知道某些假设（如目标函数的光滑性、某种统计分布等），那么特定算法可能会在某些情况下优于其他算法。
NFL 定理的启示
没有“万能”的机器学习算法，必须根据具体任务选择合适的模型。
数据的分布和问题结构决定了算法的优劣，因此领域知识、特征工程和数据处理至关重要。
如果完全不了解问题的分布，所有算法的测试误差期望相同，这意味着仅仅依赖模型优化可能不会带来真正的改进。

## 4. 测试与训练误差

- **测试（泛化）误差**：越小越好（GOAL）。
- **训练（经验）误差**：在训练集上的误差。

### 4.1 评估方法

- **测试评估方法**：
  - 怎么获得测试集。
- **Hold-out**：
  - 保持数据分布的一致性（分层采样）。
  - 多次重复划分（100次随机划分）。
  - 测试集大小控制（1/5-1/3）（深度学习到0.1）。
- **K-折交叉验证法**：
  - \( k == m \)。
  - Leave-one-out LOO cross-valuation。
- **Bootstrap Sampling**：
  - 训练集与原样本集同规模，数据分布改变。
  - Out-of-bag estimation（不常用）。

### 4.2 调参

- **算法的参数**：超参数（如 layer、nero）。
- **模型的参数**：模型权重（NN）/线性参数。
- **先后顺序**。

### 4.3 性能度量

- **回归任务**：常用均方误差（MSE）。
- **分类任务**：准确率/错误率。
- **二分类任务**：分类结果混淆矩阵。
- **查准率/查全率**。

## 5. 分类问题指标

### 5.1 分类结果混淆矩阵

| 真实情况 |      预测结果      |                    |
| :------: | :----------------: | :----------------: |
|          |      **正例**      |      **反例**      |
| **正例** | \( TP \)（真正例） | \( FN \)（假反例） |
| **反例** | \( FP \)（假正例） | \( TN \)（真反例） |

### 5.2 分类评估指标（检索任务）

- **查准率（Precision）**：
  \[
  P = \frac{TP}{TP + FP}
  \]

- **查全率（Recall）**：
  \[
  R = \frac{TP}{TP + FN}
  \]

![image](https://github.com/user-attachments/assets/33fe5b4c-a8c6-4ec0-92f0-14ec313d5380)
![image](https://github.com/user-attachments/assets/0208da16-6434-425e-bf5d-fb66e1bfb763)
![image](https://github.com/user-attachments/assets/d6bd9a07-1f08-43d4-be0e-f3a8d19d31c0)

### 5.3 ROC 曲线面积（AUC）

在二分类任务中，**ROC（Receiver Operating Characteristic）曲线** 及其面积 **AUC（Area Under Curve）** 是常用的性能评估指标。AUC 值可以衡量模型的分类能力，而在特征选择中，它也可以用来评估单个特征的好坏。

#### 5.3.1 ROC 曲线的基本概念

ROC 曲线描述了 **模型的真正率（Recall）和假正率（FPR）之间的关系**：

- **真正率（TPR）= 查全率（Recall）**
  \[
  TPR = \frac{TP}{TP + FN}
  \]
  代表所有真实正例中被正确分类为正例的比例。

- **假正率（FPR）**
  \[
  FPR = \frac{FP}{FP + TN}
  \]
  代表所有真实反例中被错误分类为正例的比例。

ROC 曲线是通过调整**分类阈值**来绘制的，它展示了模型在不同阈值下的 TPR 和 FPR 变化情况。

#### 5.3.2 AUC 代表特征的区分能力

AUC（ROC 曲线下的面积）是衡量模型分类能力的一个指标，其值在 \( [0,1] \) 之间：

- **AUC = 0.5** ：模型等效于随机猜测，特征对分类无贡献。
- **AUC > 0.5** ：特征对分类有一定的区分能力，越接近 1 说明区分能力越强。
- **AUC = 1.0** ：特征完美区分正例和反例，表示无分类错误。
- **AUC < 0.5** ：模型的预测方向错误（如果 AUC 很小，可能需要反转特征的使用方式）。

AUC 直观地可以解释为：**随机抽取一个正例和一个反例，模型正确将正例排在反例之前的概率**。

如果一个特征的 AUC 高，说明它在不同类别之间的分布区分度较好，因此是一个好的特征。

#### 5.3.3 AUC 如何衡量特征的优劣

对于单个特征 \( X \)，如果我们用它来做二分类预测（如使用逻辑回归），那么：

1. 如果 \( X \) 能很好地区分正负样本，则不同类别的 \( X \) 值分布有较大间隔，AUC 接近 1。
2. 如果 \( X \) 和类别无关，正负样本的 \( X \) 值混杂在一起，则 AUC 接近 0.5，说明这个特征无效。
3. 如果 \( X \) 反向相关（错误分类的可能性更高），AUC 可能接近 0，但可以通过反转特征值（取负）来修正。

**示例**：

- **好特征（AUC≈0.9）**：正样本的特征值大多比负样本高，ROC 曲线远离随机猜测线（对角线）。
- **中等特征（AUC≈0.7）**：特征对分类有帮助，但区分度一般。
- **无效特征（AUC≈0.5）**：特征不能提供有效信息，模型相当于随机猜测。

#### 5.3.4 AUC 在特征选择中的应用

在特征工程或特征筛选阶段，我们可以计算每个特征的 AUC：

- **高 AUC（接近 1）**：该特征对分类有很强的区分能力，应该保留。
- **中等 AUC（0.6-0.8）**：该特征有一定的区分能力，可以结合其他特征进一步分析。
- **低 AUC（接近 0.5）**：该特征对分类任务贡献很小，可能可以删除。
- **非常低 AUC（<0.5）**：该特征可能有反向作用，考虑取反或重新评估。

通过筛选高 AUC 特征，可以减少无关变量的影响，提高模型的性能和训练效率。

#### 5.3.5 结论

AUC 能够反映特征的好坏，因为：

1. **AUC 衡量了特征区分正负样本的能力**，AUC 高意味着特征更有助于分类。
2. **AUC 衡量了特征的排序能力**，AUC 高说明特征值能将正负样本正确排序。
3. **AUC 适用于非均衡数据集**，相比于精确率或查全率，它不依赖于特定的阈值，能提供更稳定的评价。

因此，在机器学习特征选择过程中，**AUC 是衡量单个特征是否有用的一个重要指标**。

---
![image](https://github.com/user-attachments/assets/0dcff4d7-2131-472e-a922-9b760fb50ab7)
![image](https://github.com/user-attachments/assets/0e24ef35-b3c6-4afc-906f-e59d2a5ed162)



## 6. 线性模型

### 6.1 线性回归

- **回归的法线**。
- **分类**。

### 6.2 多元问题

- 如果数据完美吻合线性关联，需要多少个样本直接确定模型参数？（2）
- 在噪声情况下，MSE。

![image](https://github.com/user-attachments/assets/6f3194e1-f405-4dee-8475-bd21d64b785e)
![image](https://github.com/user-attachments/assets/60610022-a58e-4df4-898c-62e16f28e573)
![image](https://github.com/user-attachments/assets/7513c29c-8782-4cd9-8c86-86904d53160f)

